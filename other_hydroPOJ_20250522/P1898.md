<h2>Description</h2><p>In 1948 Claude E. Shannon in "The Mathematical Theory of Communication"' has introduced his famous formula for the entropy of a discrete set of probabilities p1, ... , p</p><sub>n</sub><p>: 
</p><center><pre><font size="5">H=-¡Æp<sub>i</sub>log<sub>2</sub>p<sub>i</sub></font></pre></center><p>
</p>We will apply this formula to an arbitrary text string by letting p<sub>i</sub><p> be the relative frequencies of occurrence of characters in the string. For example, the entropy of the string "Northeastern European Regional Contest" with the length of 38 characters (including 3 spaces) is 3.883 with 3 digits after decimal point. The following table shows relative frequencies and the corresponding summands for the entropy of this string.
</p><center><img src="images/1898_1.jpg"></center><p>
</p>Your task is to find a string with the given entropy.  <h2>Input</h2><p>The input consists of a single real number H (0.00 &lt;= H &lt;= 6.00) with 2 digits after decimal point. </p><h2>Output</h2><p>Write to the output file a line with a single string of at least one and up to 1000 characters '0'-'9', 'a'-'z', 'A'-'Z', '.' (dot), and spaces. This string must have the entropy within 0.005 of H. </p><pre><code class="language-input1">3.88
</code></pre><pre><code class="language-output1">Northeastern European Regional Contest
</code></pre><h2>Source</h2><a href="searchproblem?field=source&amp;key=Northeastern+Europe+2003">Northeastern Europe 2003</a>